{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CAFFE_DIR = '../scripts/caffe'\n",
    "\n",
    "import sys\n",
    "sys.path.append(CAFFE_DIR + '/python')\n",
    "\n",
    "nickname = 'nick_goodey'\n",
    "board_name = 'under-the-sea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_and_crop(img_path, modified_path, size, crop_type='top'):\n",
    "    \"\"\"\n",
    "    Resize and crop an image to fit the specified size.\n",
    "    args:\n",
    "        img_path: path for the image to resize.\n",
    "        modified_path: path to store the modified image.\n",
    "        size: `(width, height)` tuple.\n",
    "        crop_type: can be 'top', 'middle' or 'bottom', depending on this\n",
    "            value, the image will cropped getting the 'top/left', 'midle' or\n",
    "            'bottom/rigth' of the image to fit the size.\n",
    "    raises:\n",
    "        Exception: if can not open the file in img_path of there is problems\n",
    "            to save the image.\n",
    "        ValueError: if an invalid `crop_type` is provided.\n",
    "    \"\"\"\n",
    "    # If height is higher we resize vertically, if not we resize horizontally\n",
    "    img = Image.open(img_path)\n",
    "    # Get current and desired ratio for the images\n",
    "    img_ratio = img.size[0] / float(img.size[1])\n",
    "    ratio = size[0] / float(size[1])\n",
    "    #The image is scaled/cropped vertically or horizontally depending on the ratio\n",
    "    if ratio > img_ratio:\n",
    "        img = img.resize((size[0], size[0] * img.size[1] / img.size[0]),\n",
    "                Image.ANTIALIAS)\n",
    "        # Crop in the top, middle or bottom\n",
    "        if crop_type == 'top':\n",
    "            box = (0, 0, img.size[0], size[1])\n",
    "        elif crop_type == 'middle':\n",
    "            box = (0, (img.size[1] - size[1]) / 2, img.size[0], (img.size[1] + size[1]) / 2)\n",
    "        elif crop_type == 'bottom':\n",
    "            box = (0, img.size[1] - size[1], img.size[0], img.size[1])\n",
    "        else :\n",
    "            raise ValueError('ERROR: invalid value for crop_type')\n",
    "        img = img.crop(box)\n",
    "    elif ratio < img_ratio:\n",
    "        img = img.resize((size[1] * img.size[0] / img.size[1], size[1]),\n",
    "                Image.ANTIALIAS)\n",
    "        # Crop in the top, middle or bottom\n",
    "        if crop_type == 'top':\n",
    "            box = (0, 0, size[0], img.size[1])\n",
    "        elif crop_type == 'middle':\n",
    "            box = ((img.size[0] - size[0]) / 2, 0, (img.size[0] + size[0]) / 2, img.size[1])\n",
    "        elif crop_type == 'bottom':\n",
    "            box = (img.size[0] - size[0], 0, img.size[0], img.size[1])\n",
    "        else :\n",
    "            raise ValueError('ERROR: invalid value for crop_type')\n",
    "        img = img.crop(box)\n",
    "    else :\n",
    "        img = img.resize((size[0], size[1]),\n",
    "                Image.ANTIALIAS)\n",
    "        # If the scale is the same, we do not need to crop\n",
    "    img.save(modified_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "##########################################################\n",
    "def __fetch_file(link) :\n",
    "    # user_agent  = 'curl/7.29.0'\n",
    "    # host = 'www.pinterest.com'\n",
    "    # accept = '*/*'\n",
    "    \n",
    "    url = link\n",
    "    # user_agent = 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "    # values = {}\n",
    "    # headers = {\"User-Agent\" : user_agent, \"Host\" : host, \"Accept\" : accept} #{'User-Agent' : user_agent }\n",
    "    # headers = {} #{'User-Agent' : user_agent }\n",
    "    # data = urllib.urlencode(values)\n",
    "    req = urllib2.Request(url) #, data, headers)\n",
    "    response = urllib2.urlopen(req)\n",
    "    the_page = response.read()\n",
    "    return the_page\n",
    "\n",
    "#########################################################\n",
    "def get_link(nickname, board_name):\n",
    "    return 'https://www.pinterest.com/' + nickname + '/' + board_name + '/'\n",
    "\n",
    "#########################################################\n",
    "def get_dir(nickname, board_name):\n",
    "    return 'out/' + nickname + '/' + board_name + '/'\n",
    "\n",
    "##########################################################\n",
    "def ensure_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "##########################################################\n",
    "def fetch_images(nickname, board_name):\n",
    "    url = get_link(nickname, board_name)\n",
    "    dir = get_dir(nickname, board_name)\n",
    "    ensure_dir(dir)\n",
    "    \n",
    "    html_code = __fetch_file(url)\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "\n",
    "    for link in soup.find_all('img'):\n",
    "        if not link.has_attr(\"class\"):\n",
    "            continue\n",
    "        if not \"pinImg\" in link[\"class\"]:\n",
    "            continue\n",
    "        time.sleep(0.1)\n",
    "        link = link[\"src\"]\n",
    "        filename = link[link.rindex(\"/\"):]\n",
    "        with open(dir + filename + '.tmp', 'wb+') as f:\n",
    "            f.write(__fetch_file(link))\n",
    "\n",
    "        resize_and_crop(\n",
    "          dir + filename + '.tmp',\n",
    "          dir + filename,\n",
    "          (256, 256),\n",
    "          crop_type='middle'\n",
    "        )\n",
    "\n",
    "\n",
    "##########################################################\n",
    "def remove_download(nickname, board_name):\n",
    "    dir = 'out/' + nickname + '/'\n",
    "    shutil.rmtree(dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__CLASSIFIER = None\n",
    "__TRANSFORMER = None\n",
    "\n",
    "def __init_classifier():\n",
    "    model_def = CAFFE_DIR + '/models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "    pretrained_model = CAFFE_DIR + '/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "    mean_file = CAFFE_DIR + '/python/caffe/imagenet/ilsvrc_2012_mean.npy'\n",
    "    channel_swap_data = '2,1,0'\n",
    "    input_scale = 1.0\n",
    "    raw_scale = 255.0\n",
    "    images_dim = '256,256'\n",
    "    caffe.set_mode_cpu()\n",
    "    print(\"CPU mode\")\n",
    "\n",
    "    image_dims = [int(s) for s in images_dim.split(',')]\n",
    "\n",
    "    mean, channel_swap = None, None\n",
    "    if mean_file:\n",
    "        mean = np.load(mean_file).mean(1).mean(1)\n",
    "    if channel_swap_data:\n",
    "        channel_swap = [int(s) for s in channel_swap_data.split(',')]\n",
    "\n",
    "    classifier = caffe.Net(model_def, pretrained_model, caffe.TEST)\n",
    "\n",
    "    transformer = caffe.io.Transformer({'data': classifier.blobs['data'].data.shape})\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    transformer.set_mean('data', mean) # mean pixel\n",
    "    transformer.set_raw_scale('data', raw_scale)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "    transformer.set_channel_swap('data', channel_swap)  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "    global __CLASSIFIER\n",
    "    __CLASSIFIER = classifier\n",
    "\n",
    "    global __TRANSFORMER\n",
    "    __TRANSFORMER = transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_for_dir(dir):\n",
    "    input_file = os.path.expanduser(dir)\n",
    "    ext = 'jpg'\n",
    "\n",
    "    if __CLASSIFIER is None:\n",
    "        __init_classifier()\n",
    "\n",
    "    # Load numpy array (.npy), directory glob (*.jpg), or image file.\n",
    "    if input_file.endswith('npy'):\n",
    "        print(\"Loading file: %s\" % input_file)\n",
    "        inputs = np.load(input_file)\n",
    "    elif os.path.isdir(input_file):\n",
    "        print(\"Loading folder: %s\" % input_file)\n",
    "        inputs =[caffe.io.load_image(im_f)\n",
    "                 for im_f in glob.glob(input_file + '/*.' + ext)]\n",
    "    else:\n",
    "        print(\"Loading file: %s\" % input_file)\n",
    "        inputs = [caffe.io.load_image(input_file)]\n",
    "\n",
    "    print(\"Classifying %d inputs.\" % len(inputs))\n",
    "\n",
    "    __CLASSIFIER.blobs['data'].reshape(50,3,227,227)\n",
    "    __CLASSIFIER.blobs['data'].data[...] = __TRANSFORMER.preprocess('data', inputs[0])\n",
    "    __CLASSIFIER.forward()\n",
    "    \n",
    "    return __CLASSIFIER.blobs['fc8'].data[0].tolist() + __CLASSIFIER.blobs['fc7'].data[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fetch_images(nickname, board_name)\n",
    "dir = get_dir(nickname, board_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading folder: out/nick_goodey/under-the-sea/\n",
      "Classifying 25 inputs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5096"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc8_and_fc7_features = extract_for_dir(dir)\n",
    "len(fc8_and_fc7_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}